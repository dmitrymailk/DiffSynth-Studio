{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ede0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"dim/nfs_pix2pix_1920_1080_v5\"\n",
    "# dataset_name = \"dim/nfs_pix2pix_1920_1080_v5_upscale_2x_raw\"\n",
    "# dataset_name = \"dim/nfs_pix2pix_1920_1080_v6\"\n",
    "# dataset_name = \"dim/render_nfs_4screens_6_sdxl_1_wan_mix\"\n",
    "# dataset_name = \"dim/render_nfs_4screens_5_sdxl_1_wan_mix\"\n",
    "dataset = load_dataset(\n",
    "    dataset_name,\n",
    "    cache_dir=f\"/code/dataset/{dataset_name.split('/')[-1]}\",\n",
    ")\n",
    "# dataset[\"train\"] = dataset[\"train\"].shuffle(seed=2025)\n",
    "dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42f40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Подготовка трансформаций\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "weight_dtype = torch.bfloat16\n",
    "# weight_dtype = torch.float32\n",
    "device = \"cuda\"\n",
    "resolution = 512\n",
    "valid_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            resolution,\n",
    "            interpolation=transforms.InterpolationMode.LANCZOS,\n",
    "        ),\n",
    "        transforms.CenterCrop(resolution),\n",
    "    ]\n",
    ")\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            resolution,\n",
    "            interpolation=transforms.InterpolationMode.LANCZOS,\n",
    "        ),\n",
    "        transforms.CenterCrop(resolution),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.5, 0.5, 0.5),\n",
    "            (0.5, 0.5, 0.5),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc75bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 20\n",
    "item = dataset[pos]\n",
    "source_image_name = \"input_image\"\n",
    "target_image_name = \"edited_image\"\n",
    "# Подготовка исходных изображений для визуализации и метрик\n",
    "orig_source_pil = item[source_image_name].convert(\"RGB\")\n",
    "target_pil = item[target_image_name].convert(\"RGB\")\n",
    "\n",
    "orig_source_pil = item[source_image_name].convert(\"RGB\")\n",
    "target_pil = item[target_image_name].convert(\"RGB\")\n",
    "\n",
    "source_tensor = valid_transforms(orig_source_pil)\n",
    "target_tensor = valid_transforms(target_pil)\n",
    "\n",
    "c_t = train_transforms(orig_source_pil).unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e6e2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b2b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 23:56:10,617 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from: [\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/text_encoder/model-00003-of-00004.safetensors\",\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/text_encoder/model-00002-of-00004.safetensors\",\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/text_encoder/model-00001-of-00004.safetensors\",\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/text_encoder/model-00004-of-00004.safetensors\"\n",
      "]\n",
      "Loaded model: {\n",
      "    \"model_name\": \"z_image_text_encoder\",\n",
      "    \"model_class\": \"diffsynth.models.z_image_text_encoder.ZImageTextEncoder\",\n",
      "    \"extra_kwargs\": {\n",
      "        \"model_size\": \"8B\"\n",
      "    }\n",
      "}\n",
      "Downloading Model from https://www.modelscope.cn to directory: /code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 23:56:14,880 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from: [\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/transformer/diffusion_pytorch_model-00002-of-00002.safetensors\",\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/transformer/diffusion_pytorch_model-00001-of-00002.safetensors\"\n",
      "]\n",
      "Loaded model: {\n",
      "    \"model_name\": \"flux2_dit\",\n",
      "    \"model_class\": \"diffsynth.models.flux2_dit.Flux2DiT\",\n",
      "    \"extra_kwargs\": {\n",
      "        \"guidance_embeds\": false,\n",
      "        \"joint_attention_dim\": 12288,\n",
      "        \"num_attention_heads\": 32,\n",
      "        \"num_layers\": 8,\n",
      "        \"num_single_layers\": 24\n",
      "    }\n",
      "}\n",
      "Downloading Model from https://www.modelscope.cn to directory: /code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 23:56:19,166 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from: \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/vae/diffusion_pytorch_model.safetensors\"\n",
      "Loaded model: {\n",
      "    \"model_name\": \"flux2_vae\",\n",
      "    \"model_class\": \"diffsynth.models.flux2_vae.Flux2VAE\",\n",
      "    \"extra_kwargs\": null\n",
      "}\n",
      "No flux2_text_encoder models available. This is not an error.\n",
      "Using z_image_text_encoder from [\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/text_encoder/model-00003-of-00004.safetensors\",\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/text_encoder/model-00002-of-00004.safetensors\",\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/text_encoder/model-00001-of-00004.safetensors\",\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/text_encoder/model-00004-of-00004.safetensors\"\n",
      "].\n",
      "Using flux2_dit from [\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/transformer/diffusion_pytorch_model-00002-of-00002.safetensors\",\n",
      "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/transformer/diffusion_pytorch_model-00001-of-00002.safetensors\"\n",
      "].\n",
      "Using flux2_vae from \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B/vae/diffusion_pytorch_model.safetensors\".\n",
      "Downloading Model from https://www.modelscope.cn to directory: /code/auto_remaster/sandbox/DiffSynth-Studio/models/black-forest-labs/FLUX.2-klein-9B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 23:56:21,957 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 tensors are fused by LoRA. Fused LoRA layers cannot be cleared by `pipe.clear_lora()`.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "os.environ[\"DIFFSYNTH_MODEL_BASE_PATH\"] = (\n",
    "    \"/code/auto_remaster/sandbox/DiffSynth-Studio/models/\"\n",
    ")\n",
    "from diffsynth.pipelines.flux2_image import Flux2ImagePipeline, ModelConfig\n",
    "import torch\n",
    "\n",
    "vram_config = {\n",
    "    # \"offload_dtype\": \"disk\",\n",
    "    # \"offload_device\": \"disk\",\n",
    "    \"onload_dtype\": torch.float8_e4m3fn,\n",
    "    # \"onload_device\": \"cpu\",\n",
    "    \"preparing_dtype\": torch.float8_e4m3fn,\n",
    "    \"preparing_device\": \"cuda\",\n",
    "    \"computation_dtype\": torch.bfloat16,\n",
    "    \"computation_device\": \"cuda\",\n",
    "}\n",
    "checkpoint_path = \"auto_remaster/sandbox/DiffSynth-Studio/models/train/FLUX.2-klein-9B_lora/epoch-0.safetensors\"\n",
    "pipe = Flux2ImagePipeline.from_pretrained(\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # torch_dtype=torch.float8_e4m3fn,\n",
    "    device=\"cuda\",\n",
    "    model_configs=[\n",
    "        ModelConfig(\n",
    "            model_id=\"black-forest-labs/FLUX.2-klein-9B\",\n",
    "            origin_file_pattern=\"text_encoder/*.safetensors\",\n",
    "            computation_dtype=torch.float8_e4m3fn,\n",
    "            **{\n",
    "                # \"offload_dtype\": \"disk\",\n",
    "                # \"offload_device\": \"disk\",\n",
    "                \"onload_dtype\": torch.float8_e4m3fn,\n",
    "                # \"onload_device\": \"cpu\",\n",
    "                \"preparing_dtype\": torch.float8_e4m3fn,\n",
    "                \"preparing_device\": \"cuda\",\n",
    "                # \"computation_dtype\": torch.bfloat16,\n",
    "                \"computation_device\": \"cuda\",\n",
    "            },\n",
    "        ),\n",
    "        ModelConfig(\n",
    "            model_id=\"black-forest-labs/FLUX.2-klein-9B\",\n",
    "            origin_file_pattern=\"transformer/*.safetensors\",\n",
    "            **vram_config,\n",
    "        ),\n",
    "        ModelConfig(\n",
    "            model_id=\"black-forest-labs/FLUX.2-klein-9B\",\n",
    "            origin_file_pattern=\"vae/diffusion_pytorch_model.safetensors\",\n",
    "            **vram_config,\n",
    "        ),\n",
    "    ],\n",
    "    tokenizer_config=ModelConfig(\n",
    "        model_id=\"black-forest-labs/FLUX.2-klein-9B\", origin_file_pattern=\"tokenizer/\"\n",
    "    ),\n",
    ")\n",
    "pipe.load_lora(pipe.dit, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b5e123",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "\"mul_cuda\" not implemented for 'Float8_e4m3fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m prompt = \u001b[33m\"\u001b[39m\u001b[33mmake this image photorealistic\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m image = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# edit_image=\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mc_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# image.save(\"image.jpg\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/utils/_contextlib.py:124\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# pyrefly: ignore [bad-context-manager]\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/diffsynth/pipelines/flux2_image.py:134\u001b[39m, in \u001b[36mFlux2ImagePipeline.__call__\u001b[39m\u001b[34m(self, prompt, negative_prompt, cfg_scale, embedded_guidance, input_image, denoising_strength, edit_image, edit_image_auto_resize, height, width, seed, rand_device, num_inference_steps, progress_bar_cmd)\u001b[39m\n\u001b[32m    120\u001b[39m inputs_shared = {\n\u001b[32m    121\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcfg_scale\u001b[39m\u001b[33m\"\u001b[39m: cfg_scale,\n\u001b[32m    122\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33membedded_guidance\u001b[39m\u001b[33m\"\u001b[39m: embedded_guidance,\n\u001b[32m   (...)\u001b[39m\u001b[32m    131\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnum_inference_steps\u001b[39m\u001b[33m\"\u001b[39m: num_inference_steps,\n\u001b[32m    132\u001b[39m }\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.units:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     inputs_shared, inputs_posi, inputs_nega = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munit_runner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_shared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_posi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_nega\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Denoise\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;28mself\u001b[39m.load_models_to_device(\u001b[38;5;28mself\u001b[39m.in_iteration_models)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/diffsynth/diffusion/base_pipeline.py:435\u001b[39m, in \u001b[36mPipelineUnitRunner.__call__\u001b[39m\u001b[34m(self, unit, pipe, inputs_shared, inputs_posi, inputs_nega)\u001b[39m\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m unit.input_params:\n\u001b[32m    434\u001b[39m         processor_inputs[name] = inputs_shared.get(name)\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m processor_outputs = \u001b[43munit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprocessor_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m inputs_posi.update(processor_outputs)\n\u001b[32m    437\u001b[39m \u001b[38;5;66;03m# Negative side\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/diffsynth/pipelines/flux2_image.py:479\u001b[39m, in \u001b[36mFlux2Unit_Qwen3PromptEmbedder.process\u001b[39m\u001b[34m(self, pipe, prompt)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[32m    478\u001b[39m pipe.load_models_to_device(\u001b[38;5;28mself\u001b[39m.onload_model_names)\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m prompt_embeds, text_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_encoder_qwen3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mprompt_embeds\u001b[39m\u001b[33m\"\u001b[39m: prompt_embeds, \u001b[33m\"\u001b[39m\u001b[33mtext_ids\u001b[39m\u001b[33m\"\u001b[39m: text_ids}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/diffsynth/pipelines/flux2_image.py:454\u001b[39m, in \u001b[36mFlux2Unit_Qwen3PromptEmbedder.encode_prompt\u001b[39m\u001b[34m(self, text_encoder, tokenizer, prompt, dtype, device, num_images_per_prompt, prompt_embeds, max_sequence_length)\u001b[39m\n\u001b[32m    451\u001b[39m prompt = [prompt] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m prompt\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompt_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     prompt_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_qwen3_prompt_embeds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_encoder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_sequence_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_sequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m batch_size, seq_len, _ = prompt_embeds.shape\n\u001b[32m    464\u001b[39m prompt_embeds = prompt_embeds.repeat(\u001b[32m1\u001b[39m, num_images_per_prompt, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/diffsynth/pipelines/flux2_image.py:402\u001b[39m, in \u001b[36mFlux2Unit_Qwen3PromptEmbedder.get_qwen3_prompt_embeds\u001b[39m\u001b[34m(self, text_encoder, tokenizer, prompt, dtype, device, max_sequence_length)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     output = \u001b[43mtext_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# Only use outputs from intermediate layers and stack them\u001b[39;00m\n\u001b[32m    410\u001b[39m out = torch.stack(\n\u001b[32m    411\u001b[39m     [output.hidden_states[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hidden_states_layers], dim=\u001b[32m1\u001b[39m\n\u001b[32m    412\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/diffsynth/models/z_image_text_encoder.py:74\u001b[39m, in \u001b[36mZImageTextEncoder.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/transformers/utils/generic.py:1002\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1000\u001b[39m             outputs = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m         outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1004\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1005\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1006\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1007\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:435\u001b[39m, in \u001b[36mQwen3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    432\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    448\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    449\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    450\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/transformers/modeling_layers.py:93\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m         logger.warning_once(message)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/transformers/utils/generic.py:955\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper.<locals>.make_capture_wrapper.<locals>.wrapped_forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mhidden_states\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(collected_outputs[key]) == \u001b[32m0\u001b[39m:\n\u001b[32m    954\u001b[39m     collected_outputs[key] += (args[\u001b[32m0\u001b[39m],)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m output = \u001b[43morig_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    957\u001b[39m     collected_outputs[key] += (output,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:321\u001b[39m, in \u001b[36mQwen3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    310\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    311\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    318\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    319\u001b[39m ) -> torch.Tensor:\n\u001b[32m    320\u001b[39m     residual = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m    323\u001b[39m     hidden_states, _ = \u001b[38;5;28mself\u001b[39m.self_attn(\n\u001b[32m    324\u001b[39m         hidden_states=hidden_states,\n\u001b[32m    325\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    331\u001b[39m         **kwargs,\n\u001b[32m    332\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/code/auto_remaster/sandbox/DiffSynth-Studio/.venv_diff/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:63\u001b[39m, in \u001b[36mQwen3RMSNorm.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m     61\u001b[39m variance = hidden_states.pow(\u001b[32m2\u001b[39m).mean(-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     62\u001b[39m hidden_states = hidden_states * torch.rsqrt(variance + \u001b[38;5;28mself\u001b[39m.variance_epsilon)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mNotImplementedError\u001b[39m: \"mul_cuda\" not implemented for 'Float8_e4m3fn'"
     ]
    }
   ],
   "source": [
    "prompt = \"make this image photorealistic\"\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    seed=0,\n",
    "    num_inference_steps=40,\n",
    "    cfg_scale=4,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    # edit_image=\n",
    "    input_image=c_t,\n",
    ")\n",
    "# image.save(\"image.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_diff (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
